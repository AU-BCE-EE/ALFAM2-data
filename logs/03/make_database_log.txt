
> # Load data from uptakes 1 and 2 (the original "ALFAM2" work)
> 
> idat.old <- read.csv('../../data-output/02/ALFAM2_interval.csv')

> pdat.old <- read.csv('../../data-output/02/ALFAM2_plot.csv')

> # 
> 
> # Date record
> print(Sys.time())
[1] "2022-03-15 14:33:59 EDT"

> # Read and check data from files
> ddir <- list.dirs('../../data-submitted/03', recursive = FALSE)

> dat <- list()

> for(i in ddir) {
+   cat('Directory ', i,'\n')
+   f <- list.files(i, pattern = 'xls', full.names = TRUE)
+   # Omit temporary Excel files (created  .... [TRUNCATED] 
Directory  ../../data-submitted/03/AU 
[1] "../../data-submitted/03/AU/ALFAM2_JNK_2019_Aug_5_5_b.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_JNK_2019_Aug_5_5_b.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_JNK_2019_May_5_6_a.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_JNK_2019_May_5_6_a.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_5_2_210929_JP_CanadianData.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_210929_JP_CanadianData.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18ABC.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18ABC.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18GHI.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18GHI.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18KLRS.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18KLRS.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18NOP.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18NOP.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_19BCHI.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_19BCHI.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_6_0_220126_JP_20CD21A_JP.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_6_0_220126_JP_20CD21A_JP.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_6_0_220310_JP_20EFGH_v2.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_6_0_220310_JP_20EFGH_v2.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_6_1_220310_JP_21CD22A.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_6_1_220310_JP_21CD22A.xlsx 
Directory  ../../data-submitted/03/UNINA 
[1] "../../data-submitted/03/UNINA/ALFAM2_UNINA_5_6_1_ver6.xlsx"
   file  ../../data-submitted/03/UNINA/ALFAM2_UNINA_5_6_1_ver6.xlsx 
Directory  ../../data-submitted/03/WUR 

> cat('Done! Read', length(dat), ' directories\n')
Done! Read 3  directories

> print(warnings())
NULL

> # Check for errors and create a log before merge
> 
> for (i in names(dat)) {
+   for (j in names(dat[[i]])) {
+ 
+     # Check for errors and creat .... [TRUNCATED] 

> # Sort out plot-level flags, using flags from emis/int
> 
> for (i in names(dat)) {
+   for (j in names(dat[[i]])) {
+ 
+     dat[[i]][[j]] <- fixFl .... [TRUNCATED] 

> # Pull new data from list
> 
> # Stack individual interval and plot level data frames from each file together
> pdat <- idat <- data.frame()

> # Extract and stack plot and interval level data
> for (i in dat) {
+   for (j in i) {
+     pdat <- rbindf(pdat, j$plots)
+     idat <- rbindf(idat .... [TRUNCATED] 

> # Add plot and institute ID codes to new data
> 
> # Extract and reuse old institute codes
> inst.old <- unique(pdat.old[, c('institute', 'inst')])

> pdat <- merge(pdat, inst.old, by = 'institute', all.x = TRUE)

> # Create completley new 300s codes for new institutes
> # NTS: needs tweak to leave out inst codes already recognized so e.g., 301 is not skipped
>  .... [TRUNCATED] 

> # ID codes created in plots data frame and then merged into interval level data frame
> # Experiment ID
> pdat$eid <- as.integer(factor(pdat$ceid))  .... [TRUNCATED] 

> # Add plot and plot x meas tech IDs
> pdat$pid <- as.integer(factor(pdat$cpid)) + max(pdat.old$pid)

> pdat$pmid <- as.integer(factor(pdat$cpmid)) + max(pdat.old$pmid)

> # Merge into interval level data
> idat <- merge(idat, pdat[, c('institute', 'file', 'exper', 'inst', 'eid', 'pid', 'pmid')], by = c('institute', 'f .... [TRUNCATED] 

> # Add observation ID
> idat <- idat[order(idat$pmid, idat$int), ]

> idat$oid <- 1:nrow(idat) + max(idat.old$oid)

> # Combine new (uptake 3) with old data
> 
> # First plot-level data
> # Rename some old columns
> names(pdat.old)[names(pdat.old) %in% c('first.row. .... [TRUNCATED] 

> names(pdat.old)[names(pdat.old) == 'database'] <- 'uptake'

> names(pdat.old)[names(pdat.old) == 'notes'] <- 'notes.plot'

> names(pdat.old)[names(pdat.old) == 'flag'] <- 'flag.plot'

> # And drop others
> pdat.old$man.freeNH3 <- pdat.old$man.eq.gasNH3 <- NULL

> # Combine
> pdat.comb <- rbindf(pdat, pdat.old)

> # Select and order columns (and order rows)
> pdat.comb <- pdat.comb[order(pdat.comb$pmid), 
+   c('inst', 'eid', 'pid', 'pmid', 
+     'uptake', 'p .... [TRUNCATED] 

> # Round
> pdat.comb <- rounddf(pdat.comb, 5, func = signif)

> ## Checks:
> ## Columns missing in new data
> #names(pdat.old)[!names(pdat.old) %in% intersect(names(pdat), names(pdat.old))]
> ## Columns missing i .... [TRUNCATED] 

> # Interval-level data
> # Remove some old columns
> idat.old$man.freeNH3 <- idat.old$man.eq.gasNH3 <- NULL

> # Rename some old columns
> names(idat.old)[names(idat.old) == 'row.in.file'] <- 'row.in.file.int'

> names(idat.old)[names(idat.old) == 'database'] <- 'uptake'

> names(idat.old)[names(idat.old) == 'notes'] <- 'notes.int'

> names(idat.old)[names(idat.old) == 'flag'] <- 'flag.int'

> # Combine
> idat.comb <- rbindf(idat, idat.old)

> # Order and select columns for database distribution
> # Note that objective is to keep file size small, so most columns in plot-level data frame ar .... [TRUNCATED] 

> # Add int suffix to weather height info (because it is also in plot data frame, pulled from emis row 1)
> names(idat.comb)[names(idat.comb) %in% c(' .... [TRUNCATED] 

> # Round 
> idat.comb <- rounddf(idat.comb, 5, func = signif)

> ## Checks
> ## Columns missing in new data
> #names(idat.old)[!names(idat.old) %in% intersect(names(idat), names(idat.old))]
> ## Columns missing in .... [TRUNCATED] 

> # Write regular csv files
> write.csv(pdat.comb, '../../data-output/03/ALFAM2_plot.csv', row.names = FALSE)

> write.csv(idat.comb, '../../data-output/03/ALFAM2_interval.csv', row.names = FALSE)

> # And then compress them
> R.utils::gzip('../../data-output/03/ALFAM2_plot.csv', overwrite = TRUE)

> R.utils::gzip('../../data-output/03/ALFAM2_interval.csv', overwrite = TRUE)
