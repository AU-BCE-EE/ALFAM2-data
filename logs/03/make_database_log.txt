
> # Load data from uptakes 1 and 2 (the original "ALFAM2" work)
> 
> idat.old <- read.csv('../../data-output/02/ALFAM2_interval.csv')

> pdat.old <- read.csv('../../data-output/02/ALFAM2_plot.csv')

> # 
> 
> # Date record
> print(Sys.time())
[1] "2022-02-07 14:52:06 EST"

> # Read and check data from files
> ddir <- list.dirs('../../data-submitted/03', recursive = FALSE)

> dat <- list()

> for(i in ddir) {
+   cat('Directory ', i,'\n')
+   f <- list.files(i, pattern = 'xls', full.names = TRUE)
+   # Omit temporary Excel files (created  .... [TRUNCATED] 
Directory  ../../data-submitted/03/AU 
[1] "../../data-submitted/03/AU/ALFAM2_JNK_2019_Aug_5_5_b.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_JNK_2019_Aug_5_5_b.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_JNK_2019_May_5_6_a.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_JNK_2019_May_5_6_a.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_5_2_210929_JP_CanadianData.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_210929_JP_CanadianData.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18ABC.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18ABC.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18GHI.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18GHI.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18KLRS.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18KLRS.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18NOP.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18NOP.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_19BCHI.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_19BCHI.xlsx 
[1] "../../data-submitted/03/AU/ALFAM2_template_6_0_220126_JP_20CD21A_JP.xlsx"
   file  ../../data-submitted/03/AU/ALFAM2_template_6_0_220126_JP_20CD21A_JP.xlsx 
Directory  ../../data-submitted/03/UNINA 
[1] "../../data-submitted/03/UNINA/ALFAM2_UNINA_5_6_1_ver6.xlsx"
   file  ../../data-submitted/03/UNINA/ALFAM2_UNINA_5_6_1_ver6.xlsx 
Directory  ../../data-submitted/03/WUR 

> cat('Done! Read', length(dat), ' directories\n')
Done! Read 3  directories

> print(warnings())
NULL

> # Pull new data from list
> 
> # Stack individual interval and plot level data frames from each file together
> pdat <- idat <- data.frame()

> # Extract and stack plot and interval level data
> for (i in dat) {
+   for (j in i) {
+     pdat <- rbindf(pdat, j$plots)
+     idat <- rbindf(idat .... [TRUNCATED] 

> # Add plot and institute ID codes to new data
> 
> # Extract and reuse old institute codes
> inst.old <- unique(pdat.old[, c('institute', 'inst')])

> pdat <- merge(pdat, inst.old, by = 'institute', all.x = TRUE)

> # Create completley new 300s codes for new institutes
> # NTS: needs tweak to leave out inst codes already recognized so e.g., 301 is not skipped
>  .... [TRUNCATED] 

> # ID codes created in plots data frame and then merged into interval level data frame
> # Experiment ID
> pdat$eid <- as.integer(factor(pdat$ceid))  .... [TRUNCATED] 

> # Add plot and plot x meas tech IDs
> pdat$pid <- as.integer(factor(pdat$cpid)) + max(pdat.old$pid)

> pdat$pmid <- as.integer(factor(pdat$cpmid)) + max(pdat.old$pmid)

> # Merge into interval level data
> idat <- merge(idat, pdat[, c('institute', 'file', 'exper', 'inst', 'eid', 'pid', 'pmid')], by = c('institute', 'f .... [TRUNCATED] 

> # Add observation ID
> idat <- idat[order(idat$pmid, idat$int), ]

> idat$oid <- 1:nrow(idat) + max(idat.old$oid)

> # Combine new (uptake 3) with old data
> 
> # First plot-level data
> # Rename some old columns
> names(pdat.old)[names(pdat.old) %in% c('first.row. .... [TRUNCATED] 

> names(pdat.old)[names(pdat.old) == 'database'] <- 'uptake'

> # And drop others
> pdat.old$man.freeNH3 <- pdat.old$man.eq.gasNH3 <- NULL

> # Combine
> pdat.comb <- rbindf(pdat, pdat.old)

> # Select and order columns (and order rows)
> pdat.comb <- pdat.comb[order(pdat.comb$pmid), 
+   c('inst', 'eid', 'pid', 'pmid', 
+     'uptake', 'p .... [TRUNCATED] 

> # Round
> pdat.comb <- rounddf(pdat.comb, 5, func = signif)

> ## Checks:
> ## Columns missing in new data
> #names(pdat.old)[!names(pdat.old) %in% intersect(names(pdat), names(pdat.old))]
> ## Columns missing i .... [TRUNCATED] 

> # Interval-level data
> # Remove some old columns
> idat.old$man.freeNH3 <- idat.old$man.eq.gasNH3 <- NULL

> # Rename some old columns
> names(idat.old)[names(idat.old) == 'row.in.file'] <- 'row.in.file.int'

> names(idat.old)[names(idat.old) == 'database'] <- 'uptake'

> # Combine
> idat.comb <- rbindf(idat, idat.old)

> # Order and select columns for database distribution
> # Note that objective is to keep file size small, so most columns in plot-level data frame ar .... [TRUNCATED] 

> # NTS: sort out notes and flag
> 
> # Round 
> idat.comb <- rounddf(idat.comb, 5, func = signif)

> # Checks
> # Columns missing in new data
> names(idat.old)[!names(idat.old) %in% intersect(names(idat), names(idat.old))]
character(0)

> # Columns missing in old data
> names(idat)[!names(idat) %in% intersect(names(idat), names(idat.old))]
 [1] "soil.water.v"     "man.source.det"   "man.vs"           "man.vfa"         
 [5] "app.end"          "app.rate.unit"    "row.in.file.plot" "man.trt3"        
 [9] "app.end.orig"     "meas.tech.det"    "j.NH3.unit"       "pH.surf"         
[13] "soil.temp.surf"   "MOL"              "ustar"            "rl"              
[17] "air.pres"         "air.pres.unit"    "notes.emis"       "j.NH3.unit.orig" 
[21] "j.NH3.orig"       "j.NH3.conv.fact"  "cpmid"            "cpid"            
[25] "ceid"             "e"                "bta"             

> # Columns missing in combined data
> names(idat)[!names(idat) %in% intersect(names(idat), names(idat.comb))]
 [1] "institute"        "file"             "exper"            "pub.id"          
 [5] "proj"             "field"            "plot"             "rep"             
 [9] "plot.area"        "lat"              "long"             "country"         
[13] "topo"             "clay"             "silt"             "sand"            
[17] "oc"               "soil.type"        "soil.water"       "soil.water.v"    
[21] "soil.moist"       "soil.ph"          "soil.dens"        "crop.res"        
[25] "till"             "man.source"       "man.source.det"   "man.bed"         
[29] "man.con"          "man.trt1"         "man.trt2"         "man.stor"        
[33] "man.dm"           "man.vs"           "man.tkn"          "man.tan"         
[37] "man.tic"          "man.ua"           "man.vfa"          "man.ph"          
[41] "app.start"        "app.end"          "app.method"       "app.rate"        
[45] "app.rate.unit"    "incorp"           "time.incorp"      "man.area"        
[49] "dist.inj"         "furrow.z"         "furrow.w"         "crop"            
[53] "crop.z"           "crop.area"        "lai"              "row.in.file.plot"
[57] "man.trt3"         "app.start.orig"   "app.end.orig"     "tan.app"         
[61] "uptake"           "treat"            "meas.tech"        "meas.tech.det"   
[65] "j.NH3.unit"       "air.temp.z"       "soil.temp.z"      "wind.z"          
[69] "wind.loc"         "far.loc"          "notes.emis"       "j.NH3.unit.orig" 
[73] "j.NH3.orig"       "j.NH3.conv.fact"  "cpmid"            "cpid"            
[77] "ceid"             "e"                "pub.info"         "soil.type2"      
[81] "exper2"           "rep2"             "acid"             "meas.tech.orig"  
[85] "meas.tech2"       "crop.orig"        "man.source.orig"  "app.method.orig" 
[89] "app.method2"      "incorp.orig"      "date.start"       "inst"            
[93] "eid"             

> # Check for names intersection with plot-level data frame, should only be those to be used for merge 
> names(idat.comb)[names(idat.comb) %in% inter .... [TRUNCATED] 
[1] "pid"   "pmid"  "notes" "flag" 

> # NTS: weather height/location, notes, flag cols all problematic! Present in both.

> write.csv(pdat.comb, '../../data-output/03/ALFAM2_plot.csv', row.names = FALSE)

> write.csv(idat.comb, '../../data-output/03/ALFAM2_interval.csv', row.names = FALSE)
