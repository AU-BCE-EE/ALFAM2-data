
> # Load data from uptakes 1 and 2 (the original "ALFAM2" work)
> 
> idat.old <- read.csv('../../data-output/02/ALFAM2_interval.csv')

> pdat.old <- read.csv('../../data-output/02/ALFAM2_plot.csv')

> # 
> 
> # Date record
> print(Sys.time())
[1] "2022-07-07 19:44:45 EDT"

> # Read and check data from files
> ddir <- list.dirs('../../data-submitted/03', recursive = FALSE)

> dat <- list()

> for(i in ddir) {
+   cat('Directory ', i,'\n')
+   f <- list.files(i, pattern = 'xls', full.names = TRUE)
+   # Omit temporary Excel files (created  .... [TRUNCATED] 
Directory  ../../data-submitted/03/AU 
   file  ../../data-submitted/03/AU/ALFAM2_JNK_2019_Aug_5_5_b.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .[1] "File: ../../data-submitted/03/AU/ALFAM2_JNK_2019_Aug_5_5_b.xlsx"
plots:
            proj              exper field plot rep pub.id plot.area         lat
1 Vejrumbro_2019 Vejrumbro_2019_Aug          1   1 Atmos1    260000 56°27'12''N
2 Vejrumbro_2019 Vejrumbro_2019_Aug          1   1 Atmos1    260000 56°27'12''N
3 Vejrumbro_2019 Vejrumbro_2019_Aug          1   1 Atmos1    260000 56°27'12''N
4 Vejrumbro_2019 Vejrumbro_2019_Aug          1   1 Atmos1    260000 56°27'12''N
        long country
1 9°32'26''E      DK
2 9°32'26''E      DK
3 9°32'26''E      DK
4 9°32'26''E      DK
plots.orig:
            proj pub.id              exper field plot rep plot.area         lat
1 Vejrumbro_2019 Atmos1 Vejrumbro_2019_Aug          1   1    260000 56°27'12''N
        long country
1 9°32'26''E      DK
Unique emis:
              proj              exper field plot rep   treat meas.tech
1   Vejrumbro_2019 Vejrumbro_2019_Aug          1   1 CRDS_1m       bLS
323 Vejrumbro_2019 Vejrumbro_2019_Aug          1   1 CRDS_2m       bLS
645 Vejrumbro_2019 Vejrumbro_2019_Aug          1   1      MD       bLS
967 Vejrumbro_2019 Vejrumbro_2019_Aug          1   1     AGM       AGM
    meas.tech.det
1         CRDS_1m
323       CRDS_2m
645            MD
967          <NA>
Number of rows changed after plots/emis merge in cleanALAM()
May be entry error or multiple treatments per plot (no error)Problem is often caused by plot/rep entry error. Get in here with browser() and look at:
unique(plots.orig[, c('plot', 'rep')]) 
unique(emis[, c('plot', 'rep')])   file  ../../data-submitted/03/AU/ALFAM2_JNK_2019_May_5_6_a.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .[1] "File: ../../data-submitted/03/AU/ALFAM2_JNK_2019_May_5_6_a.xlsx"
plots:
            proj              exper field plot rep pub.id plot.area         lat
1 Vejrumbro_2019 Vejrumbro_2019_May          1   1 Atmos1    260000 56°27'12''N
2 Vejrumbro_2019 Vejrumbro_2019_May          1   1 Atmos1    260000 56°27'12''N
3 Vejrumbro_2019 Vejrumbro_2019_May          1   1 Atmos1    260000 56°27'12''N
        long country
1 9°32'26''E      DK
2 9°32'26''E      DK
3 9°32'26''E      DK
plots.orig:
            proj pub.id              exper field plot rep plot.area         lat
1 Vejrumbro_2019 Atmos1 Vejrumbro_2019_May          1   1    260000 56°27'12''N
        long country
1 9°32'26''E      DK
Unique emis:
              proj              exper field plot rep   treat meas.tech
1   Vejrumbro_2019 Vejrumbro_2019_May          1   1 CRDS_1m       bLS
278 Vejrumbro_2019 Vejrumbro_2019_May          1   1 CRDS_2m       bLS
555 Vejrumbro_2019 Vejrumbro_2019_May          1   1     AGM       bLS
    meas.tech.det
1         CRDS_1m
278       CRDS_1m
555       CRDS_1m
Number of rows changed after plots/emis merge in cleanALAM()
May be entry error or multiple treatments per plot (no error)Problem is often caused by plot/rep entry error. Get in here with browser() and look at:
unique(plots.orig[, c('plot', 'rep')]) 
unique(emis[, c('plot', 'rep')])   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_210929_JP_CanadianData.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18ABC.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18GHI.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18KLRS.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_18NOP.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .   file  ../../data-submitted/03/AU/ALFAM2_template_5_2_211012_JP_19BCHI.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .   file  ../../data-submitted/03/AU/ALFAM2_template_6_0_220126_JP_20CD21A_JP.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .   file  ../../data-submitted/03/AU/ALFAM2_template_6_0_220310_JP_20EFGH_v2.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .   file  ../../data-submitted/03/AU/ALFAM2_template_6_1_220317_JP_21CD22A.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .   file  ../../data-submitted/03/AU/ALFAM2_template_6_1_220524_JP_21E_220610.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .   file  ../../data-submitted/03/AU/ALFAM2_template_6_1_eGylle_JK_3.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .Did not find any publication info. . . might be good to double-check spreadsheet.
# A tibble: 1 × 1
  ``   
  <chr>
1 .    
   file  ../../data-submitted/03/AU/ALFAM2_template_6.1 SGS(Rev).xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .Did not find any publication info. . . might be good to double-check spreadsheet.
# A tibble: 26 × 18
      `` ``    ``    ``    ``    ``    ``    ``    ``    ``    ``    ``    ``   
   <dbl> <chr> <lgl> <lgl> <lgl> <lgl> <lgl> <lgl> <lgl> <lgl> <lgl> <lgl> <lgl>
 1     1 "3.\… NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
 2    NA  <NA> NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
 3    NA  <NA> NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
 4    NA  <NA> NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
 5    NA  <NA> NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
 6    NA  <NA> NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
 7    NA  <NA> NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
 8    NA  <NA> NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
 9    NA  <NA> NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
10    NA  <NA> NA    NA    NA    NA    NA    NA    NA    NA    NA    NA    NA   
# … with 16 more rows, and 5 more variables: `` <dbl>, `` <dbl>, `` <dbl>,
#   `` <dbl>, `` <dbl>
Directory  ../../data-submitted/03/DiSSA-IT 
   file  ../../data-submitted/03/DiSSA-IT/ALFAM2_data from Adani-Zilio_2.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .Directory  ../../data-submitted/03/INIA 
Directory  ../../data-submitted/03/UNINA 
   file  ../../data-submitted/03/UNINA/ALFAM2_UNINA_5_6_1_ver6.xlsx 
  Starting. . .  Submitter info . . .  Contributors . . .  Experiments . . .  Treatments . . .  Plots . . .  Emission . . .  Publications . . .Directory  ../../data-submitted/03/WUR 

> cat('Done! Read', length(dat), ' directories\n')
Done! Read 5  directories

> print(warnings())
Warning message:
In normalizePath("~") : path[1]="/sbuild-nonexistent": No such file or directory

> # Check for errors and create a log before merge
> 
> for (i in names(dat)) {
+   for (j in names(dat[[i]])) {
+ 
+     # Check for errors and creat .... [TRUNCATED] 

> # Sort out int- and plot-level flags
> 
> for (i in names(dat)) {
+   for (j in names(dat[[i]])) {
+ 
+     dat[[i]][[j]] <- addFlags(dat[[i]][[j]]) .... [TRUNCATED] 

> # Pull new data from list
> 
> # Stack individual interval and plot level data frames from each file together
> pdat <- idat <- data.frame()

> # Extract and stack plot and interval level data
> for (i in dat) {
+   for (j in i) {
+     pdat <- rbindf(pdat, j$plots)
+     idat <- rbindf(idat .... [TRUNCATED] 

> # Add plot and institute ID codes to new data
> 
> # Extract and reuse old institute codes
> inst.old <- unique(pdat.old[, c('institute', 'inst')])

> pdat <- merge(pdat, inst.old, by = 'institute', all.x = TRUE)

> # Create completley new 300s codes for new institutes
> # NTS: needs tweak to leave out inst codes already recognized so e.g., 301 is not skipped
>  .... [TRUNCATED] 

> # ID codes created in plots data frame and then merged into interval level data frame
> # Experiment ID (includes uptake, inst, proj, exper)
> pdat$ .... [TRUNCATED] 

> # Add plot and plot x meas tech IDs
> pdat$pid <- as.integer(factor(pdat$cpid)) + max(pdat.old$pid)

> pdat$pmid <- as.integer(factor(pdat$cpmid)) + max(pdat.old$pmid)

> # Merge IDs into interval level data
> # Should alternatively be able to switch to interger directly in idat
> idat <- merge(idat, pdat[, c('cpmid', .... [TRUNCATED] 

> # Add observation ID
> idat <- idat[order(idat$pmid, idat$int), ]

> idat$oid <- 1:nrow(idat) + max(idat.old$oid)

> # Combine new (uptake 3) with old data
> 
> # First plot-level data
> # Rename some old columns
> names(pdat.old)[names(pdat.old) %in% c('first.row. .... [TRUNCATED] 

> names(pdat.old)[names(pdat.old) == 'row.in.file'] <- 'row.in.file.plot'

> names(pdat.old)[names(pdat.old) == 'database'] <- 'uptake'

> names(pdat.old)[names(pdat.old) == 'notes'] <- 'notes.plot'

> names(pdat.old)[names(pdat.old) == 'flag'] <- 'flag.plot'

> # And drop others
> pdat.old$man.freeNH3 <- pdat.old$man.eq.gasNH3 <- NULL

> # Combine
> pdat.comb <- rbindf(pdat, pdat.old)

> # Select and order columns (and order rows)
> pdat.comb <- pdat.comb[order(pdat.comb$pmid), 
+   c('inst', 'eid', 'pid', 'pmid', 
+     'uptake', 'p .... [TRUNCATED] 

> # Round
> pdat.comb <- rounddf(pdat.comb, 5, func = signif)

> ## Checks:
> ## Columns missing in new data
> #names(pdat.old)[!names(pdat.old) %in% intersect(names(pdat), names(pdat.old))]
> ## Columns missing i .... [TRUNCATED] 

> # Interval-level data
> # Remove some old columns
> idat.old$man.freeNH3 <- idat.old$man.eq.gasNH3 <- NULL

> # Rename some old columns
> names(idat.old)[names(idat.old) == 'row.in.file'] <- 'row.in.file.int'

> names(idat.old)[names(idat.old) == 'database'] <- 'uptake'

> names(idat.old)[names(idat.old) == 'notes'] <- 'notes.int'

> names(idat.old)[names(idat.old) == 'flag'] <- 'flag.int'

> # Combine
> idat.comb <- rbindf(idat, idat.old)

> # Order and select columns for database distribution
> # Note that objective is to keep file size small, so most columns in plot-level data frame ar .... [TRUNCATED] 

> # Add int suffix to weather height info (because it is also in plot data frame, pulled from emis row 1)
> nn <- c('soil.temp.z', 'air.temp.z', 'wind .... [TRUNCATED] 

> names(idat.comb)[names(idat.comb) %in% nn] <- paste0(nn, '.int')

> # Round 
> idat.comb <- rounddf(idat.comb, 5, func = signif)

> ## Checks
> ## Columns missing in new data
> #names(idat.old)[!names(idat.old) %in% intersect(names(idat), names(idat.old))]
> ## Columns missing in .... [TRUNCATED] 

> knit('check_final.Rmd', output = '../../logs/03/check_final.md')
  |                                                                              |                                                                      |   0%  |                                                                              |.......................                                               |  33%
   inline R code fragments

  |                                                                              |...............................................                       |  67%
label: unnamed-chunk-1
  |                                                                              |......................................................................| 100%
  ordinary text without R code


[1] "../../logs/03/check_final.md"

> # Write regular csv files
> write.csv(pdat.comb, '../../data-output/03/ALFAM2_plot.csv', row.names = FALSE)

> write.csv(idat.comb, '../../data-output/03/ALFAM2_interval.csv', row.names = FALSE)

> # And then compress them
> R.utils::gzip('../../data-output/03/ALFAM2_plot.csv', overwrite = TRUE)

> R.utils::gzip('../../data-output/03/ALFAM2_interval.csv', overwrite = TRUE)
